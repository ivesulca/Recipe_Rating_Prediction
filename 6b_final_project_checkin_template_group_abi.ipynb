{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Final-Project-Check-in\" data-toc-modified-id=\"Final-Project-Check-in-1\">Final Project Check-in</a></span></li><li><span><a href=\"#Group-Name\" data-toc-modified-id=\"Group-Name-2\">Group Name</a></span></li><li><span><a href=\"#Student-Names\" data-toc-modified-id=\"Student-Names-3\">Student Names</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-4\">Load Data</a></span></li><li><span><a href=\"#Fit-scikit-learn-model\" data-toc-modified-id=\"Fit-scikit-learn-model-5\">Fit scikit-learn model</a></span></li><li><span><a href=\"#Evaluation-Metric\" data-toc-modified-id=\"Evaluation-Metric-6\">Evaluation Metric</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Project Check-in\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Name\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Grace Hoppers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Names\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Akansha Shrivastava\n",
    "2. Ivette Sulca\n",
    "3. Bing Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import imblearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import geonamescache  #sudo pip install geonamescache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = pd.read_csv('../../data/epi_r.csv')\n",
    "data_json = pd.read_json('../../data/full_format_recipes.json',)\n",
    "#data_pd = pd.read_csv('data/epi_r.csv')\n",
    "#data_json = pd.read_json('data/full_format_recipes.json',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting null predictive variables from the dataset\n",
    "data_pd = data_pd.loc[(data_pd.rating>0) & (~data_pd.rating.isna())]\n",
    "\n",
    "# Deleting drinks\n",
    "data_pd = data_pd.loc[(data_pd.drink==0) & (data_pd.drinks==0) & (data_pd.cocktail==0)]\n",
    "\n",
    "# Deleting repeated titles\n",
    "data_pd.drop_duplicates(subset=['title'], inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove target, \"rating\", from data_pd\n",
    "y = data_pd.iloc[:,1]\n",
    "data_pd = pd.concat([data_pd.iloc[:,0], data_pd.iloc[:,2:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature: holidays: Dummy for world holiday \n",
    "# (a celebratory day attached to date in calendar-- birthday, graduation, anniversary, etc. not included)\n",
    "holidays = [\"bastille day\", \"christmas\", \"christmas eve\", \"cinco de mayo\", \"columbus\", \n",
    " \"diwali\", \"easter\", \"father's day\", \"fourth of july\", \"friendsgiving\", \"halloween\",\n",
    " \"hanukkah\", \"kwanzaa\", \"labor day\", \"lunar new year\", \"mother's day\", \"new year's day\",\n",
    " \"new year's eve\", \"oktoberfest\", \"passover\", \"persian new year\", \"purim\", \"ramadan\", \n",
    " \"rosh hashanah/yom kippur\", \"st. patrick's day\", \"sukkot\", \"thanksgiving\", \n",
    " \"valentine's day\"]\n",
    "\n",
    "data_pd[\"holiday\"] = np.where(data_pd[holidays].sum(axis=1)>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FAT: In grams but it can mislead depending of the number of portions (Paella for example)\n",
    "\n",
    "#Delete bigger portions(Paella) and outliers\n",
    "y = y.loc[((data_pd.fat>=0) & (data_pd.fat<=200)) | (data_pd.fat.isna())]\n",
    "data_pd = data_pd.loc[((data_pd.fat>=0) & (data_pd.fat<=200)) | (data_pd.fat.isna())]\n",
    "\n",
    "#Median imputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "fat_clean = imp.fit_transform(data_pd.fat.values.reshape(-1,1))\n",
    "fat_clean = pd.DataFrame(data=fat_clean, columns=['fat_clean'])\n",
    "data_pd['fat'] = fat_clean.fat_clean.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROTEIN CLEANING\n",
    "\n",
    "#Again, considering values lower than 200: deleting 62 rows...\n",
    "y = y.loc[((data_pd.protein>=0) & (data_pd.protein<=200)) | (data_pd.protein.isna())]\n",
    "data_pd = data_pd.loc[((data_pd.protein>=0) & (data_pd.protein<=200)) | (data_pd.protein.isna())]\n",
    "\n",
    "#Median imputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "protein_clean = imp.fit_transform(data_pd.protein.values.reshape(-1,1))\n",
    "protein_clean = pd.DataFrame(data=protein_clean ,columns=['protein_clean'])\n",
    "data_pd['protein']=protein_clean.protein_clean.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SODIUM\n",
    "\n",
    "#Unit: miligrams\n",
    "#Very different values, so we will impute only:\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "sodium_clean = imp.fit_transform(data_pd.sodium.values.reshape(-1,1))\n",
    "sodium_clean = pd.DataFrame(data=sodium_clean ,columns=['sodium_clean'])\n",
    "data_pd['sodium']=sodium_clean.sodium_clean.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering columns related to \"healthy\"\n",
    "\n",
    "# selecting all the relevant columns\n",
    "\n",
    "selected = [\"fat free\", \"healthy\", \"low cal\", \"quick and healthy\", \n",
    "\"low carb\",\n",
    "\"low cholesterol\",\n",
    "\"low fat\",\n",
    "\"low sodium\",\n",
    "\"low sugar\",\n",
    "\"low/no sugar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering rows which have \"selected\" columns as 1 -> healthy\n",
    "data_pd[\"allhealthy\"] = 0\n",
    "for col in selected:\n",
    "    data_pd.loc[data_pd[col] == 1, \"allhealthy\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing missing values in calories by mean\n",
    "\n",
    "median = data_pd[\"calories\"].median()\n",
    "data_pd.loc[data_pd[\"calories\"].isna(), \"calories\"] = median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding complexity preparation from JSON file\n",
    "\n",
    "data_json.drop_duplicates(subset=['title'],inplace=True)  \n",
    "data_json['directions_n_characters']=data_json['directions'].astype(str).str.len()\n",
    "data_json['ingredients_quantity']=data_json['ingredients'].str.len()\n",
    "data_json['directions_n_steps']=data_json['directions'].astype(str).str.replace('[','').str.replace(']','').str.split(\"',\").apply(lambda x: len(x))\n",
    "data_json.loc[data_json.desc.isna(), \"desc_n_characters\"] = 0\n",
    "data_json.loc[data_json.desc.notna(), \"desc_n_characters\"] = data_json[\"desc\"].astype(str).str.len()\n",
    "\n",
    "data_json2=data_json[['title','directions_n_characters','ingredients_quantity',\n",
    "                      'directions_n_steps', 'desc_n_characters']]\n",
    "\n",
    "data_pd=pd.merge(data_pd, data_json2, on='title', how=\"left\")\n",
    "\n",
    "#Change by imputer\n",
    "#Median imputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "directions_n_characters = imp.fit_transform(data_pd.directions_n_characters.values.reshape(-1,1))\n",
    "directions_n_characters = pd.DataFrame(data=directions_n_characters ,columns=['directions_n_characters'])\n",
    "data_pd['directions_n_characters']=directions_n_characters.directions_n_characters.values\n",
    "\n",
    "\n",
    "ingredients_quantity = imp.fit_transform(data_pd.ingredients_quantity.values.reshape(-1,1))\n",
    "ingredients_quantity = pd.DataFrame(data=ingredients_quantity ,columns=['ingredients_quantity'])\n",
    "data_pd['ingredients_quantity']=ingredients_quantity.ingredients_quantity.values\n",
    "\n",
    "\n",
    "directions_n_steps = imp.fit_transform(data_pd.directions_n_steps.values.reshape(-1,1))\n",
    "directions_n_steps = pd.DataFrame(data=directions_n_steps ,columns=['directions_n_steps'])\n",
    "data_pd['directions_n_steps']=directions_n_steps.directions_n_steps.values\n",
    "\n",
    "\n",
    "desc_n_characters = imp.fit_transform(data_pd.desc_n_characters.values.reshape(-1,1))\n",
    "desc_n_characters = pd.DataFrame(data=desc_n_characters ,columns=['desc_n_characters'])\n",
    "data_pd['desc_n_characters']=desc_n_characters.desc_n_characters.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15437, 685)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying locations:\n",
    "column_names=np.array(data_pd.columns)\n",
    "column_names=[c.strip().upper() for c in column_names]\n",
    "\n",
    "gc = geonamescache.GeonamesCache()\n",
    "countries = gc.get_countries_by_names()\n",
    "cities = gc.get_cities()\n",
    "states = gc.get_us_states()\n",
    "\n",
    "dict_countries=dict()\n",
    "for k,v in countries.items():\n",
    "    dict_countries[k.upper()]=[v['geonameid'],v['iso'],v['iso3']]\n",
    "\n",
    "dict_countries2=dict()\n",
    "for k,v in countries.items():\n",
    "    dict_countries2[v['iso'].upper()]=k.upper()\n",
    "\n",
    "dict_cities=dict()\n",
    "for k,v in cities.items():\n",
    "    dict_cities[v['name'].upper()]=[v['geonameid'],v['countrycode']]\n",
    "\n",
    "dict_states=dict()    \n",
    "for k,v in states.items():\n",
    "    dict_states[v['name'].upper()] = [v['geonameid'],v['code'], 'US' ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dummy variable of if there is a location listed or not\n",
    "\n",
    "#1. Identifying countries, states and cities\n",
    "\n",
    "locs=[]\n",
    "for col in data_pd.columns:    \n",
    "    if col.upper() in dict_countries:\n",
    "        if col.upper() not in ['TURKEY']:\n",
    "#            data_pd.loc[data_pd[col]==1,'country_id'] = dict_countries[col.upper()][1]\n",
    "#            data_pd.loc[data_pd[col]==1,'country_name'] = col.upper()   \n",
    "            locs.append(col)\n",
    " \n",
    "\n",
    "    if col.upper() in dict_states:        \n",
    "#        data_pd.loc[data_pd[col]==1,'state_id'] = dict_states[col.upper()][1]\n",
    "#        data_pd.loc[data_pd[col]==1,'state_name'] = col.upper()   \n",
    "#        data_pd.loc[data_pd[col]==1,'country_id'] = 'US'\n",
    "#        data_pd.loc[data_pd[col]==1,'country_name'] = 'UNITED STATES' \n",
    "        locs.append(col)\n",
    " \n",
    "    if col.upper() in dict_cities:     \n",
    "        if col.upper() not in ['SPRING','ORANGE','WALNUT','LEEK','WEDDING','PLUM','TEQUILA','DATE','PAPAYA','MARSALA','SAKE','RYE','GOUDA','HOLIDAY']:\n",
    " #           data_pd.loc[data_pd[col]==1,'city_id'] = dict_cities[col.upper()][0]\n",
    " #           data_pd.loc[data_pd[col]==1,'city_name'] = col.upper()   \n",
    " #           data_pd.loc[data_pd[col]==1,'country_id'] = dict_cities[col.upper()][1]\n",
    " #           data_pd.loc[data_pd[col]==1,'country_name'] = dict_countries2[dict_cities[col.upper()][1]] \n",
    "            locs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd[\"locations\"] = np.where(data_pd[locs].sum(axis=1)>0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit scikit-learn model\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the below features in the model:\n",
    "X = data_pd[[\"calories\", \"fat\", \"protein\", \"sodium\", \"22-minute meals\",\n",
    "             \"3-ingredient recipes\", \"holiday\", \"allhealthy\",\n",
    "             \"directions_n_characters\", \"ingredients_quantity\",\n",
    "             \"directions_n_steps\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    6966\n",
       "4    4479\n",
       "6    2044\n",
       "3    1281\n",
       "2     445\n",
       "0     123\n",
       "1      99\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y (rating) only appears as 6 different floats between 1 and 4\n",
    "# Convert floats to categorical variables, 0 to 6, for classification\n",
    "\n",
    "y_discrete = pd.cut(y, bins=7, labels=np.arange(7), right=False)\n",
    "y_discrete.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_discrete, test_size=0.20, stratify=y_discrete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating pipelines\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "                ('clf', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_kn = Pipeline([('scl', StandardScaler()),\n",
    "                ('clf', KNeighborsClassifier())])\n",
    "\n",
    "pipe_nb = Pipeline([\n",
    "                ('clf', GaussianNB())])\n",
    "\n",
    "pipe_svc = Pipeline([#('scl', StandardScaler()),\n",
    "                ('clf', SVC(random_state=42))])\n",
    "\n",
    "pipe_rc = Pipeline([\n",
    "                ('clf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "pipelines=[pipe_lr,pipe_kn,pipe_nb,pipe_svc,pipe_rc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivettesulca/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/ivettesulca/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/ivettesulca/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/ivettesulca/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Training the pipelines\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        98\n",
      "           1       0.00      0.00      0.00        79\n",
      "           2       0.00      0.00      0.00       356\n",
      "           3       0.00      0.00      0.00      1025\n",
      "           4       0.38      0.01      0.01      3583\n",
      "           5       0.45      1.00      0.62      5573\n",
      "           6       0.25      0.00      0.00      1635\n",
      "\n",
      "    accuracy                           0.45     12349\n",
      "   macro avg       0.15      0.14      0.09     12349\n",
      "weighted avg       0.35      0.45      0.28     12349\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivettesulca/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.11      0.16        98\n",
      "           1       0.26      0.08      0.12        79\n",
      "           2       0.36      0.15      0.22       356\n",
      "           3       0.42      0.27      0.33      1025\n",
      "           4       0.50      0.61      0.55      3583\n",
      "           5       0.61      0.73      0.67      5573\n",
      "           6       0.51      0.16      0.25      1635\n",
      "\n",
      "    accuracy                           0.56     12349\n",
      "   macro avg       0.43      0.30      0.33     12349\n",
      "weighted avg       0.54      0.56      0.53     12349\n",
      "\n",
      "GaussianNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.01      0.02        98\n",
      "           1       0.00      0.00      0.00        79\n",
      "           2       0.00      0.00      0.00       356\n",
      "           3       0.10      0.48      0.17      1025\n",
      "           4       0.29      0.01      0.02      3583\n",
      "           5       0.49      0.62      0.54      5573\n",
      "           6       0.27      0.05      0.08      1635\n",
      "\n",
      "    accuracy                           0.33     12349\n",
      "   macro avg       0.18      0.17      0.12     12349\n",
      "weighted avg       0.35      0.33      0.28     12349\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivettesulca/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.89        98\n",
      "           1       1.00      0.68      0.81        79\n",
      "           2       1.00      0.79      0.88       356\n",
      "           3       1.00      0.84      0.92      1025\n",
      "           4       0.95      0.94      0.95      3583\n",
      "           5       0.91      0.99      0.95      5573\n",
      "           6       1.00      0.87      0.93      1635\n",
      "\n",
      "    accuracy                           0.94     12349\n",
      "   macro avg       0.98      0.85      0.90     12349\n",
      "weighted avg       0.94      0.94      0.94     12349\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        98\n",
      "           1       1.00      0.96      0.98        79\n",
      "           2       1.00      0.97      0.98       356\n",
      "           3       0.99      0.97      0.98      1025\n",
      "           4       0.97      0.98      0.98      3583\n",
      "           5       0.97      0.99      0.98      5573\n",
      "           6       0.99      0.94      0.97      1635\n",
      "\n",
      "    accuracy                           0.98     12349\n",
      "   macro avg       0.99      0.96      0.97     12349\n",
      "weighted avg       0.98      0.98      0.98     12349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for pipe in pipelines:\n",
    "    y_pred = pipe.predict(X_train)\n",
    "    \n",
    "    model_name=pipe.get_params()['clf'].__class__.__name__\n",
    "    \n",
    "    print(model_name)\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivettesulca/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  79    0    0    0    4   15    0]\n",
      " [   0   54    0    0    7   17    1]\n",
      " [   0    0  280    0   17   59    0]\n",
      " [   0    0    0  865   42  116    2]\n",
      " [   0    0    0    0 3380  200    3]\n",
      " [   0    0    0    0   43 5529    1]\n",
      " [   0    0    0    0   57  162 1416]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.89        98\n",
      "           1       1.00      0.68      0.81        79\n",
      "           2       1.00      0.79      0.88       356\n",
      "           3       1.00      0.84      0.92      1025\n",
      "           4       0.95      0.94      0.95      3583\n",
      "           5       0.91      0.99      0.95      5573\n",
      "           6       1.00      0.87      0.93      1635\n",
      "\n",
      "    accuracy                           0.94     12349\n",
      "   macro avg       0.98      0.85      0.90     12349\n",
      "weighted avg       0.94      0.94      0.94     12349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    3   22    0]\n",
      " [   0    0    0    0    1   19    0]\n",
      " [   0    0    0    0    3   86    0]\n",
      " [   0    0    1    0   20  234    1]\n",
      " [   0    0    0    0   46  846    4]\n",
      " [   0    0    2    1   45 1342    3]\n",
      " [   0    0    1    0   30  378    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        25\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.00      0.00      0.00        89\n",
      "           3       0.00      0.00      0.00       256\n",
      "           4       0.31      0.05      0.09       896\n",
      "           5       0.46      0.96      0.62      1393\n",
      "           6       0.00      0.00      0.00       409\n",
      "\n",
      "    accuracy                           0.45      3088\n",
      "   macro avg       0.11      0.14      0.10      3088\n",
      "weighted avg       0.30      0.45      0.31      3088\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivettesulca/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metric\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    3   22    0]\n",
      " [   0    0    0    0    1   19    0]\n",
      " [   0    0    0    0    3   86    0]\n",
      " [   0    0    1    0   20  234    1]\n",
      " [   0    0    0    0   46  846    4]\n",
      " [   0    0    2    1   45 1342    3]\n",
      " [   0    0    1    0   30  378    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        25\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.00      0.00      0.00        89\n",
      "           3       0.00      0.00      0.00       256\n",
      "           4       0.31      0.05      0.09       896\n",
      "           5       0.46      0.96      0.62      1393\n",
      "           6       0.00      0.00      0.00       409\n",
      "\n",
      "    accuracy                           0.45      3088\n",
      "   macro avg       0.11      0.14      0.10      3088\n",
      "weighted avg       0.30      0.45      0.31      3088\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivettesulca/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted F1 score overall:  0.101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivettesulca/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Unweighted F1 score overall: \", round(f1_score(y_test, y_pred, average='macro'), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
