{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Final-Project-Check-in\" data-toc-modified-id=\"Final-Project-Check-in-1\">Final Project Check-in</a></span></li><li><span><a href=\"#Group-Name\" data-toc-modified-id=\"Group-Name-2\">Group Name</a></span></li><li><span><a href=\"#Student-Names\" data-toc-modified-id=\"Student-Names-3\">Student Names</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-4\">Load Data</a></span></li><li><span><a href=\"#Fit-scikit-learn-model\" data-toc-modified-id=\"Fit-scikit-learn-model-5\">Fit scikit-learn model</a></span></li><li><span><a href=\"#Evaluation-Metric\" data-toc-modified-id=\"Evaluation-Metric-6\">Evaluation Metric</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Project Check-in\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Name\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Grace Hoppers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Names\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Akansha Shrivastava\n",
    "2. Ivette Sulca\n",
    "3. Bing Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import imblearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import geonamescache  #sudo pip install geonamescache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_pd = pd.read_csv('../../data/epi_r.csv')\n",
    "# data_json = pd.read_json('../../data/full_format_recipes.json',)\n",
    "data_pd = pd.read_csv('data/epi_r.csv')\n",
    "data_json = pd.read_json('data/full_format_recipes.json',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting null predictive variables from the dataset\n",
    "data_pd = data_pd.loc[(data_pd.rating>0) & (~data_pd.rating.isna())]\n",
    "\n",
    "# Deleting drinks\n",
    "data_pd = data_pd.loc[(data_pd.drink==0) & (data_pd.drinks==0) & (data_pd.cocktail==0)]\n",
    "\n",
    "# Deleting repeted titles\n",
    "data_pd.drop_duplicates(subset=['title'], inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove target, \"rating\", from data_pd\n",
    "data_pd = pd.concat([data_pd.iloc[:,0], data_pd.iloc[:,2:]], axis=1)\n",
    "y = data_pd.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature: holidays: Dummy for world holiday \n",
    "# (a celebratory day attached to date in calendar-- birthday, graduation, anniversary, etc. not included)\n",
    "holidays = [\"bastille day\", \"christmas\", \"christmas eve\", \"cinco de mayo\", \"columbus\", \n",
    " \"diwali\", \"easter\", \"father's day\", \"fourth of july\", \"friendsgiving\", \"halloween\",\n",
    " \"hanukkah\", \"kwanzaa\", \"labor day\", \"lunar new year\", \"mother's day\", \"new year's day\",\n",
    " \"new year's eve\", \"oktoberfest\", \"passover\", \"persian new year\", \"purim\", \"ramadan\", \n",
    " \"rosh hashanah/yom kippur\", \"st. patrick's day\", \"sukkot\", \"thanksgiving\", \n",
    " \"valentine's day\"]\n",
    "\n",
    "data_pd[\"holiday\"] = np.where(data_pd[holidays].sum(axis=1)>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FAT: In grams but it can mislead depending of the number of portions (Paella for example)\n",
    "\n",
    "#Delete bigger portions(Paella) and outliers\n",
    "y = y.loc[((data_pd.fat>=0) & (data_pd.fat<=200)) | (data_pd.fat.isna())]\n",
    "data_pd = data_pd.loc[((data_pd.fat>=0) & (data_pd.fat<=200)) | (data_pd.fat.isna())]\n",
    "\n",
    "#Median imputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "fat_clean = imp.fit_transform(data_pd.fat.values.reshape(-1,1))\n",
    "fat_clean = pd.DataFrame(data=fat_clean, columns=['fat_clean'])\n",
    "data_pd['fat'] = fat_clean.fat_clean.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROTEIN CLEANING\n",
    "\n",
    "#Again, considering values lower than 200: deleting 62 rows...\n",
    "y = y.loc[((data_pd.protein>=0) & (data_pd.protein<=200)) | (data_pd.protein.isna())]\n",
    "data_pd = data_pd.loc[((data_pd.protein>=0) & (data_pd.protein<=200)) | (data_pd.protein.isna())]\n",
    "\n",
    "#Median imputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "protein_clean = imp.fit_transform(data_pd.protein.values.reshape(-1,1))\n",
    "protein_clean = pd.DataFrame(data=protein_clean ,columns=['protein_clean'])\n",
    "data_pd['protein']=protein_clean.protein_clean.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SODIUM\n",
    "\n",
    "#Unit: miligrams\n",
    "#Very different values, so we will impute only:\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "sodium_clean = imp.fit_transform(data_pd.sodium.values.reshape(-1,1))\n",
    "sodium_clean = pd.DataFrame(data=sodium_clean ,columns=['sodium_clean'])\n",
    "data_pd['sodium']=sodium_clean.sodium_clean.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering columns related to \"healthy\"\n",
    "\n",
    "# selecting all the relevant columns\n",
    "\n",
    "selected = [\"fat free\", \"healthy\", \"low cal\", \"quick and healthy\", \n",
    "\"low carb\",\n",
    "\"low cholesterol\",\n",
    "\"low fat\",\n",
    "\"low sodium\",\n",
    "\"low sugar\",\n",
    "\"low/no sugar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering rows which have \"selected\" columns as 1 -> healthy\n",
    "data_pd[\"allhealthy\"] = 0\n",
    "for col in selected:\n",
    "    data_pd.loc[data_pd[col] == 1, \"allhealthy\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing missing values in calories by mean\n",
    "\n",
    "median = data_pd[\"calories\"].median()\n",
    "data_pd.loc[data_pd[\"calories\"].isna(), \"calories\"] = median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding complexity preparation from JSON file\n",
    "\n",
    "data_json.drop_duplicates(subset=['title'],inplace=True)  \n",
    "data_json['directions_n_characters']=data_json['directions'].astype(str).str.len()\n",
    "data_json['ingredients_quantity']=data_json['ingredients'].str.len()\n",
    "data_json['directions_n_steps']=data_json['directions'].astype(str).str.replace('[','').str.replace(']','').str.split(\"',\").apply(lambda x: len(x))\n",
    "data_json.loc[data_json.desc.isna(), \"desc_n_characters\"] = 0\n",
    "data_json.loc[data_json.desc.notna(), \"desc_n_characters\"] = data_json[\"desc\"].astype(str).str.len()\n",
    "\n",
    "data_json2=data_json[['title','directions_n_characters','ingredients_quantity',\n",
    "                      'directions_n_steps', 'desc_n_characters']]\n",
    "\n",
    "data_pd=pd.merge(data_pd, data_json2, on='title', how=\"left\")\n",
    "\n",
    "#Change by imputer\n",
    "data_pd.loc[data_pd.directions_n_steps.isna(),'directions_n_steps']=0\n",
    "data_pd.loc[data_pd.ingredients_quantity.isna(),'ingredients_quantity']=0\n",
    "data_pd.loc[data_pd.directions_n_characters.isna(),'directions_n_characters']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15437, 685)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying locations:\n",
    "column_names=np.array(data_pd.columns)\n",
    "column_names=[c.strip().upper() for c in column_names]\n",
    "\n",
    "gc = geonamescache.GeonamesCache()\n",
    "countries = gc.get_countries_by_names()\n",
    "cities = gc.get_cities()\n",
    "states = gc.get_us_states()\n",
    "\n",
    "dict_countries=dict()\n",
    "for k,v in countries.items():\n",
    "    dict_countries[k.upper()]=[v['geonameid'],v['iso'],v['iso3']]\n",
    "\n",
    "dict_countries2=dict()\n",
    "for k,v in countries.items():\n",
    "    dict_countries2[v['iso'].upper()]=k.upper()\n",
    "\n",
    "dict_cities=dict()\n",
    "for k,v in cities.items():\n",
    "    dict_cities[v['name'].upper()]=[v['geonameid'],v['countrycode']]\n",
    "\n",
    "dict_states=dict()    \n",
    "for k,v in states.items():\n",
    "    dict_states[v['name'].upper()] = [v['geonameid'],v['code'], 'US' ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dummy variable of if there is a location listed or not\n",
    "\n",
    "#1. Identifying countries, states and cities\n",
    "\n",
    "list_col_drop=[]\n",
    "for col in data_pd.columns:    \n",
    "    if col.upper() in dict_countries:\n",
    "        if col.upper() not in ['TURKEY']:\n",
    "#            data_pd.loc[data_pd[col]==1,'country_id'] = dict_countries[col.upper()][1]\n",
    "#            data_pd.loc[data_pd[col]==1,'country_name'] = col.upper()   \n",
    "            list_col_drop.append(col)\n",
    " \n",
    "\n",
    "    if col.upper() in dict_states:        \n",
    "#        data_pd.loc[data_pd[col]==1,'state_id'] = dict_states[col.upper()][1]\n",
    "#        data_pd.loc[data_pd[col]==1,'state_name'] = col.upper()   \n",
    "#        data_pd.loc[data_pd[col]==1,'country_id'] = 'US'\n",
    "#        data_pd.loc[data_pd[col]==1,'country_name'] = 'UNITED STATES' \n",
    "        list_col_drop.append(col)\n",
    " \n",
    "    if col.upper() in dict_cities:     \n",
    "        if col.upper() not in ['SPRING','ORANGE','WALNUT','LEEK','WEDDING','PLUM','TEQUILA','DATE','PAPAYA','MARSALA','SAKE','RYE','GOUDA','HOLIDAY']:\n",
    " #           data_pd.loc[data_pd[col]==1,'city_id'] = dict_cities[col.upper()][0]\n",
    " #           data_pd.loc[data_pd[col]==1,'city_name'] = col.upper()   \n",
    " #           data_pd.loc[data_pd[col]==1,'country_id'] = dict_cities[col.upper()][1]\n",
    " #           data_pd.loc[data_pd[col]==1,'country_name'] = dict_countries2[dict_cities[col.upper()][1]] \n",
    "            list_col_drop.append(col)\n",
    "\n",
    "#2. Dropping individual location columns\n",
    "#data_pd=data_pd.drop(list_col_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd[\"locations\"] = np.where(data_pd[list_col_drop].sum(axis=1)>0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit scikit-learn model\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the below features in the model:\n",
    "X = data_pd[[\"calories\", \"fat\", \"protein\", \"sodium\", \"22-minute meals\",\n",
    "             \"3-ingredient recipes\", \"holiday\", \"allhealthy\",\n",
    "             \"directions_n_characters\", \"ingredients_quantity\",\n",
    "             \"directions_n_steps\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calories\n",
      "False\n",
      "\n",
      "fat\n",
      "False\n",
      "\n",
      "protein\n",
      "False\n",
      "\n",
      "sodium\n",
      "False\n",
      "\n",
      "22-minute meals\n",
      "False\n",
      "\n",
      "3-ingredient recipes\n",
      "False\n",
      "\n",
      "holiday\n",
      "False\n",
      "\n",
      "allhealthy\n",
      "False\n",
      "\n",
      "directions_n_characters\n",
      "False\n",
      "\n",
      "ingredients_quantity\n",
      "False\n",
      "\n",
      "directions_n_steps\n",
      "False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in X:\n",
    "    print(col)\n",
    "    print(any(X[col].isna()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(y.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10111\n",
       "1     1896\n",
       "2      272\n",
       "3       48\n",
       "4       13\n",
       "5        9\n",
       "6        2\n",
       "Name: calories, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y (rating) only appears as 6 different floats between 1 and 4\n",
    "# Convert floats to categorical variables, 0 to 6, for classification\n",
    "\n",
    "y_discrete = pd.cut(y, bins=7, labels=np.arange(7), right=False)\n",
    "y_discrete.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3118c9a3efc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_discrete\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_discrete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2119\u001b[0m                      random_state=random_state)\n\u001b[1;32m   2120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2121\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2123\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m         \"\"\"\n\u001b[0;32m-> 1714\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1715\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_discrete, test_size=0.20, stratify=y_discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metric\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unweighted F1 score overall: \", round(f1_score(y_test, y_pred, average='macro'), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
